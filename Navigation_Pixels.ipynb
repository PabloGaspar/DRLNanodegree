{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "Congratulations for completing the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893)!  In this notebook, you will learn how to control an agent in a more challenging environment, where it can learn directly from raw pixels!  **Note that this exercise is optional!**\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/VisualBanana.app\"`\n",
    "- **Windows** (x86): `\"path/to/VisualBanana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/VisualBanana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/VisualBanana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/VisualBanana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/VisualBanana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/VisualBanana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `VisualBanana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"VisualBanana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 1\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 0\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"./VisualBanana_Windows_x86_64/Banana.exe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The environment state is an array of raw pixels with shape `(1, 84, 84, 3)`.  *Note that this code differs from the notebook for the project, where we are grabbing **`visual_observations`** (the raw pixels) instead of **`vector_observations`**.* A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1fb46736d30>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "state = env_info.visual_observations[0]\n",
    "\n",
    "image = np.squeeze(state).transpose((2, 0, 1))\n",
    "\n",
    "imshow(torch.from_numpy(image), normalize=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image (3, 84, 84)\n",
      "States have shape: (84, 84, 3)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(state))\n",
    "\n",
    "print('image', image.shape)\n",
    "\n",
    "state_size = state.shape\n",
    "print('States have shape:', np.squeeze(state).shape)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size (2, 3, 84, 84)\n",
      "tensor([[-0.0484,  0.0439,  0.0323,  0.0268],\n",
      "        [-0.0484,  0.0439,  0.0323,  0.0268]],\n",
      "       device='cuda:0', grad_fn=<ThAddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "from visual_model import QNetwork\n",
    "\n",
    "my_image = np.vstack([np.expand_dims(image, axis=0),np.expand_dims(image, axis=0)])\n",
    "print('size', my_image.shape)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "qnet = QNetwork(4, 0).to(device)\n",
    "actions = qnet(torch.from_numpy(my_image).float().to(device))\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.0\n"
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.visual_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.visual_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "from dqn_visual_agent import Agent\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finalShape (1, 3, 84, 84)\n",
      "Score: -1.0\n",
      "Episode 1\tAverage Score: -1.00finalShape (1, 3, 84, 84)\n",
      "Score: 0.0\n",
      "Episode 2\tAverage Score: -0.50finalShape (1, 3, 84, 84)\n",
      "Score: 0.0\n",
      "Episode 3\tAverage Score: -0.33finalShape (1, 3, 84, 84)\n",
      "Score: 0.0\n",
      "Episode 4\tAverage Score: -0.25finalShape (1, 3, 84, 84)\n",
      "Score: -3.0\n",
      "Episode 5\tAverage Score: -0.80finalShape (1, 3, 84, 84)\n",
      "Score: 1.0\n",
      "Episode 6\tAverage Score: -0.50finalShape (1, 3, 84, 84)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-6dc79e95cfc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[0magent\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAgent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_agent\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;31m# plot the scores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-6dc79e95cfc5>\u001b[0m in \u001b[0;36mtrain_agent\u001b[1;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mreward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m                   \u001b[1;31m# get the reward\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m                  \u001b[1;31m# see if episode has finished\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m             \u001b[0magent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mreward\u001b[0m                                \u001b[1;31m# update the score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Deep RL\\p1_navigation\\dqn_visual_agent.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[0;32m     52\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mexperiences\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlearn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexperiences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mGAMMA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mact\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Deep RL\\p1_navigation\\dqn_visual_agent.py\u001b[0m in \u001b[0;36mlearn\u001b[1;34m(self, experiences, gamma)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# Get expected Q values from local model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m         \u001b[0mQ_expected\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mqnetwork_local\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[1;31m# Compute loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Deep RL\\p1_navigation\\visual_model.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, state)\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    476\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 477\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    478\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mlinear\u001b[1;34m(input, weight, bias)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1023\u001b[0m         \u001b[1;31m# fused op is marginally faster\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1024\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1025\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def train_agent(n_episodes=1000, max_t=1500, eps_start=1.0, eps_end=0.01, eps_decay=0.995):    \n",
    "    env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "    state = env_info.visual_observations[0]            # get the current state\n",
    "    score = 0                                          # initialize the score\n",
    "    \n",
    "    \n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state = env_info.visual_observations[0] \n",
    "        state = state.transpose((0, 3, 1, 2))\n",
    "        print(\"finalShape\",state.shape)\n",
    "        score = 0\n",
    "        while True:\n",
    "            action = agent.act(state, eps)                 # select an action\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.visual_observations[0]   # get the next state\n",
    "            next_state = next_state.transpose((0, 3, 1, 2))\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward                                # update the score\n",
    "            state = next_state                             # roll over the state to next time step\n",
    "            if done:                                       # exit loop if episode finished\n",
    "                break\n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 10 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=21.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "        \n",
    "\n",
    " \n",
    "    \n",
    "agent = Agent(action_size=4, seed=0)\n",
    "scores = train_agent()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(agent.qnetwork_local.state_dict(), 'checkpointvisual.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
